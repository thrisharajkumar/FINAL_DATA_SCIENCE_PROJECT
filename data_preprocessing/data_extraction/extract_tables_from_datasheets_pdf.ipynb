{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38da1fb8",
   "metadata": {},
   "source": [
    "## This script is used to convert the pdf datasheets of each MOSFET - SiC in the form of Tables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29777e4f",
   "metadata": {},
   "source": [
    "### import libraries \n",
    "important:\n",
    "pdfplumber \n",
    "regrex expressions \n",
    "pandas \n",
    "os\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebfbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# The paths input and ouput defined here using the config \n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), \"../../../\")))\n",
    "from config import DATA_TABLES_INPUT, DATA_TABLES_OUTPUT\n",
    "\n",
    "os.makedirs(DATA_TABLES_OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ebf6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These arre the headers if the tables in the datasheets which we are using as target keywords\n",
    "target_keywords = [\n",
    "    \"maximum ratings\", \n",
    "    \"electrical characteristics\",\n",
    "    \"reverse diode\", \n",
    "    \"thermal characteristics\"\n",
    "]\n",
    "\n",
    "def clean_line_encoding(line):\n",
    "    return line.replace(\"ËšC\", \"°C\").replace(\"˚C\", \"°C\").replace(\"Â°C\", \"°C\")\n",
    "\n",
    "# Remove extra spaces in column names and table cells\n",
    "def clean_dataframe(df):\n",
    "    df.columns = [re.sub(r\"\\s+\", \"\", str(col)) for col in df.columns]\n",
    "    return df.apply(lambda col: col.map(lambda x: re.sub(r\"\\s+\", \" \", str(x)).strip() if pd.notnull(x) else x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f8d49f",
   "metadata": {},
   "source": [
    "### Finding the heading with the keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# heading in text lines that matches our target keywords \n",
    "def find_matching_heading(text_lines):\n",
    "    for line in text_lines:\n",
    "        cleaned = clean_line_encoding(line).strip().lower()\n",
    "        for keyword in target_keywords:\n",
    "            if keyword in cleaned:\n",
    "                return clean_line_encoding(line.strip()) \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ccf6d",
   "metadata": {},
   "source": [
    "### Finding the correct headers and the tables in each page in  the pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532dd0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def standardize_columns(df):\n",
    "    df.columns = [f\"Col{i+1}\" for i in range(len(df.columns))]\n",
    "    return df\n",
    "\n",
    "# All the datasheets pdf \n",
    "for filename in os.listdir(DATA_TABLES_INPUT):\n",
    "    if not filename.lower().endswith(\".pdf\"):\n",
    "        continue  \n",
    "\n",
    "    pdf_path = os.path.join(DATA_TABLES_INPUT, filename)\n",
    "    output_path = os.path.join(DATA_TABLES_OUTPUT, filename.replace(\".pdf\", \".csv\"))\n",
    "    collected_tables = []  \n",
    "\n",
    "    try:\n",
    "        # Using pdfplumber here to open the file and finf the tables here \n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                # Extracting the text lines from the page\n",
    "                text_lines = page.extract_text().split(\"\\n\") if page.extract_text() else []\n",
    "                # Extracting the tables from the page\n",
    "                tables = page.extract_tables()\n",
    "\n",
    "                for table in tables:\n",
    "                    if not table or len(table) < 2 or len(table[0]) < 2:\n",
    "                        continue\n",
    "\n",
    "                    # section heading\n",
    "                    heading = find_matching_heading(text_lines)\n",
    "                    if heading:\n",
    "                        try:\n",
    "                            df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                        except:\n",
    "                            df = pd.DataFrame(table)\n",
    "                            df = standardize_columns(df)\n",
    "\n",
    "                        # Clean table contents\n",
    "                        df = clean_dataframe(df)\n",
    "                        df = df.apply(lambda col: col.map(lambda x: clean_line_encoding(str(x)) if pd.notnull(x) else x))\n",
    "\n",
    "                        # save with the heading and the table \n",
    "                        collected_tables.append((heading, df))\n",
    "\n",
    "    # Very important to check the files processing or not here\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Save all collected tables for this PDF to a CSV\n",
    "\n",
    "    if collected_tables:\n",
    "        all_csv_data = []\n",
    "        for title, df in collected_tables:\n",
    "            # heading \n",
    "            all_csv_data.append(pd.DataFrame([[title]]))\n",
    "        \n",
    "            df = standardize_columns(df)\n",
    "            all_csv_data.append(df)\n",
    "            \n",
    "            all_csv_data.append(pd.DataFrame([[\"\"] * len(df.columns)], columns=df.columns))\n",
    "\n",
    "        # Combining all into one CSV file\n",
    "        final_df = pd.concat(all_csv_data, ignore_index=True)\n",
    "        final_df.to_csv(output_path, index=False, header=False)\n",
    "        print(f\"Extracted: {filename} to {output_path}\")\n",
    "    else:\n",
    "        print(f\"No matching tables found in {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
