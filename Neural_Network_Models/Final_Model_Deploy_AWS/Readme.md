FINAL MODEL STRUCTURE + AWS INTEGRATION MAP

Neural_Network_Models/
â””â”€â”€ Final_Deploy_AWS/
    â”œâ”€â”€ Final_Model_With_Deployment.ipynb       â—€ï¸ Main notebook for your thesis
    â”œâ”€â”€ model_artifacts/                         â—€ï¸ Output from EC2 (downloaded via scp)
    â”‚   â”œâ”€â”€ final_model.h5                       âœ… Trained ANN model
    â”‚   â”œâ”€â”€ input_scaler.pkl                     âœ… Saved input scaler
    â”‚   â”œâ”€â”€ output_scaler.pkl                    âœ… Saved dict of output scalers
    â”‚   â”œâ”€â”€ training_history.pkl                 âœ… For plotting train/val loss
    â”‚   â”œâ”€â”€ optuna_best_params.json              âœ… Best hyperparameters used
    â”‚   â”œâ”€â”€ predictions.csv                      âœ… Actual vs predicted on test/unseen
    â”‚   â”œâ”€â”€ r2_rmse_table.csv                    âœ… Evaluation metrics table
    â”‚   â”œâ”€â”€ aws_predictions.csv                  âœ… Predictions from AWS API (optional)
    â”‚
    â”œâ”€â”€ train_val_loss_curves/                   âœ… ğŸ“ˆ PNG plots
    â”‚   â””â”€â”€ train_val_loss_curve.png
    â”‚
    â”œâ”€â”€ predicted_vs_actual/                     âœ… ğŸ“‰ Line plots for unseen/test data
    â”‚   â””â”€â”€ pulse1_overshoot_plot.png
    â”‚   â””â”€â”€ pulse2_undershoot_plot.png
    â”‚
    â”œâ”€â”€ r2_rmse_tables/                          âœ… ğŸ“Š CSVs & plots of metrics
    â”‚   â””â”€â”€ r2_bar_chart.png
    â”‚   â””â”€â”€ r2_rmse_table.csv
    â”‚
    â”œâ”€â”€ lambda_function/                         âœ… ğŸ“¦ Code for AWS Lambda deployment
    â”‚   â”œâ”€â”€ lambda_function.py
    â”‚   â”œâ”€â”€ final_model.h5
    â”‚   â”œâ”€â”€ input_scaler.pkl
    â”‚   â”œâ”€â”€ output_scaler.pkl
    â”‚   â””â”€â”€ requirements.txt
    â”‚
    â”œâ”€â”€ api_test_request.ipynb                   âœ… ğŸŒ Send API requests from notebook
    â”œâ”€â”€ deploy_instructions.md                   âœ… ğŸ“„ Step-by-step guide for AWS setup

ğŸ” HOW THIS WORKS â€” STEP BY STEP
ğŸ”¹ Step 1: Run 25% Data Tests (Locally)

Folder: Baseline_ANN/, Attention_ANN/, etc.

You test:

Generalization on unseen MOSFET

Training on 25% balanced data

Log best RÂ² across all outputs

âœ… You select the best model type (e.g., Multi-Headed ANN)

ğŸ”¹ Step 2: Move Best Model to Full Training (AWS EC2)

In EC2:

Run train_final_model.py using full dataset (400K+ rows)

Save .h5, .pkl, predictions, plots, tables

âœ… Everything gets saved in ~/final_model_output/

ğŸ”¹ Step 3: Download from EC2 to Local Project

From your local terminal:

scp -i your-key.pem -r ubuntu@<ec2-ip>:~/final_model_output/ \
Neural_Network_Models/Final_Deploy_AWS/model_artifacts/


âœ… Now your local project has the full model results from AWS!

ğŸ”¹ Step 4: Load All Results in .ipynb

Inside Final_Model_With_Deployment.ipynb, you:

Load the trained model (.h5)

Load predictions and metrics CSVs

Plot training/val loss curves

Compare predicted vs actual

Load AWS predictions via API (optional)

Generate thesis-ready RÂ²/RMSE tables

ğŸ“˜ Thesis Integration

In your .ipynb:

Use ## markdown sections like:

## 1. Final Model Trained on AWS
## 2. RÂ² and RMSE Results
## 3. Generalization on Unseen MOSFET
## 4. Real-Time Inference via AWS Lambda
## 5. Conclusion


In your thesis PDF:

Export key plots (e.g. train_val_loss_curve.png)

Copy summary table from r2_rmse_table.csv

You Are Now Doing:
Phase	Tool	Location
1. Try 25% data with all models	MLP, Attention, Masked	Locally
2. Choose best generalizing model	Based on RÂ²/plots	Locally
3. Train best model on 100% data	Full ANN + Optuna	AWS EC2
4. Save results	.h5, .pkl, plots, CSVs	EC2 then download
Inference (optional)	AWS Lambda + API Gateway	Notebook
5. Final notebook	Final_Model_With_Deployment.ipynb	Locally, fully explained