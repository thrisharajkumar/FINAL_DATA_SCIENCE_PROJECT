(text_analytics) PS C:\Users\pc\Desktop\ANN> $env:PYTHONPATH="."; python src/optuna_tuner.py
>>
[I 2025-07-23 21:12:39,093] A new study created in memory with name: no-name-9a06794a-fa36-4525-98fa-5b768e60c986
2025-07-23 21:12:43.377284: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[I 2025-07-23 21:13:49,608] Trial 0 finished with value: 25.63173289381351 and parameters: {'n_layers': 2, 'n_units': 510, 'activation': 'relu', 'dropout': 0.24969689341222379, 'optimizer': 'adam', 'learning_rate': 0.0029103201274112327, 'batch_size': 1024}. Best is trial 0 with value: 25.63173289381351.
[I 2025-07-23 21:15:13,716] Trial 1 finished with value: 3.377127836072078 and parameters: {'n_layers': 1, 'n_units': 271, 'activation': 'tanh', 'dropout': 0.4532510034489086, 'optimizer': 'rmsprop', 'learning_rate': 4.5232393351698615e-05, 'batch_size': 256}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:16:04,335] Trial 2 finished with value: 31.779610288008122 and parameters: {'n_layers': 3, 'n_units': 143, 'activation': 'relu', 'dropout': 0.44802108625182235, 'optimizer': 'rmsprop', 'learning_rate': 0.002201990324930134, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:17:12,560] Trial 3 finished with value: 136.60713060648538 and parameters: {'n_layers': 4, 'n_units': 124, 'activation': 'tanh', 'dropout': 0.2565344195925826, 'optimizer': 'rmsprop', 'learning_rate': 3.028428933863324e-05, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:13:49,608] Trial 0 finished with value: 25.63173289381351 and parameters: {'n_layers': 2, 'n_units': 510, 'activation': 'relu', 'dropout': 0.24969689341222379, 'optimizer': 'adam', 'learning_rate': 0.0029103201274112327, 'batch_size': 1024}. Best is trial 0 with value: 25.63173289381351.
[I 2025-07-23 21:15:13,716] Trial 1 finished with value: 3.377127836072078 and parameters: {'n_layers': 1, 'n_units': 271, 'activation': 'tanh', 'dropout': 0.4532510034489086, 'optimizer': 'rmsprop', 'learning_rate': 4.5232393351698615e-05, 'batch_size': 256}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:16:04,335] Trial 2 finished with value: 31.779610288008122 and parameters: {'n_layers': 3, 'n_units': 143, 'activation': 'relu', 'dropout': 0.44802108625182235, 'optimizer': 'rmsprop', 'learning_rate': 0.002201990324930134, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:17:12,560] Trial 3 finished with value: 136.60713060648538 and parameters: {'n_layers': 4, 'n_units': 124, 'activation': 'tanh', 'dropout': 0.2565344195925826, 'optimizer': 'rmsprop', 'learning_rate': 3.028428933863324e-05, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
'activation': 'relu', 'dropout': 0.24969689341222379, 'optimizer': 'adam', 'learning_rate': 0.0029103201274112327, 'batch_size': 1024}. Best is trial 0 with value: 25.63173289381351.
[I 2025-07-23 21:15:13,716] Trial 1 finished with value: 3.377127836072078 and parameters: {'n_layers': 1, 'n_units': 271, 'activation': 'tanh', 'dropout': 0.4532510034489086, 'optimizer': 'rmsprop', 'learning_rate': 4.5232393351698615e-05, 'batch_size': 256}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:16:04,335] Trial 2 finished with value: 31.779610288008122 and parameters: {'n_layers': 3, 'n_units': 143, 'activation': 'relu', 'dropout': 0.44802108625182235, 'optimizer': 'rmsprop', 'learning_rate': 0.002201990324930134, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:17:12,560] Trial 3 finished with value: 136.60713060648538 and parameters: {'n_layers': 4, 'n_units': 124, 'activation': 'tanh', 'dropout': 0.2565344195925826, 'optimizer': 'rmsprop', 'learning_rate': 3.028428933863324e-05, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:15:13,716] Trial 1 finished with value: 3.377127836072078 and parameters: {'n_layers': 1, 'n_units': 271, 'activation': 'tanh', 'dropout': 0.4532510034489086, 'optimizer': 'rmsprop', 'learning_rate': 4.5232393351698615e-05, 'batch_size': 256}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:16:04,335] Trial 2 finished with value: 31.779610288008122 and parameters: {'n_layers': 3, 'n_units': 143, 'activation': 'relu', 'dropout': 0.44802108625182235, 'optimizer': 'rmsprop', 'learning_rate': 0.002201990324930134, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:17:12,560] Trial 3 finished with value: 136.60713060648538 and parameters: {'n_layers': 4, 'n_units': 124, 'activation': 'tanh', 'dropout': 0.2565344195925826, 'optimizer': 'rmsprop', 'learning_rate': 3.028428933863324e-05, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
h_size': 256}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:16:04,335] Trial 2 finished with value: 31.779610288008122 and parameters: {'n_layers': 3, 'n_units': 143, 'activation': 'relu', 'dropout': 0.44802108625182235, 'optimizer': 'rmsprop', 'learning_rate': 0.002201990324930134, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:17:12,560] Trial 3 finished with value: 136.60713060648538 and parameters: {'n_layers': 4, 'n_units': 124, 'activation': 'tanh', 'dropout': 0.2565344195925826, 'optimizer': 'rmsprop', 'learning_rate': 3.028428933863324e-05, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
 'activation': 'relu', 'dropout': 0.44802108625182235, 'optimizer': 'rmsprop', 'learning_rate': 0.002201990324930134, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:17:12,560] Trial 3 finished with value: 136.60713060648538 and parameters: {'n_layers': 4, 'n_units': 124, 'activation': 'tanh', 'dropout': 0.2565344195925826, 'optimizer': 'rmsprop', 'learning_rate': 3.028428933863324e-05, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
h_size': 512}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:17:12,560] Trial 3 finished with value: 136.60713060648538 and parameters: {'n_layers': 4, 'n_units': 124, 'activation': 'tanh', 'dropout': 0.2565344195925826, 'optimizer': 'rmsprop', 'learning_rate': 3.028428933863324e-05, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
 'activation': 'tanh', 'dropout': 0.2565344195925826, 'optimizer': 'rmsprop', 'learning_rate': 3.028428933863324e-05, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
h_size': 512}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:20:23,068] Trial 4 finished with value: 11.981314475630901 and parameters: {'n_layers': 3, 'n_units': 495, 'activation': 'tanh', 'dropout': 0.1599774159057224, 'optimizer': 'adam', 'learning_rate': 0.0005579558422603893, 'batch_size': 512}. Best is trial 1 with value: 3.377127836072078.
[I 2025-07-23 21:21:48,453] Trial 5 finished with value: 1.0799398402165805 and parameters: {'n_layers': 2, 'n_units': 429, 'activation': 'relu', 'dropout': 0.16573766837925397, 'optimizer': 'adam', 'learning_rate': 0.0032720413476746064, 'batch_size': 512}. Best is trial 5 with value: 1.0799398402165805.
[I 2025-07-23 21:24:54,384] Trial 6 finished with value: 3.7120787268575266 and parameters: {'n_layers': 4, 'n_units': 398, 'activation': 'relu', 'dropout': 0.2947430755438303, 'optimizer': 'rmsprop', 'learning_rate': 0.0001249710519219613, 'batch_size': 256}. Best is trial 5 with value: 1.0799398402165805.
[I 2025-07-23 21:26:07,185] Trial 7 finished with value: 10.424242819341409 and parameters: {'n_layers': 2, 'n_units': 65, 'activation': 'relu', 'dropout': 0.23699384409992974, 'optimizer': 'adam', 'learning_rate': 5.0988388969934746e-05, 'batch_size': 256}. Best is trial 5 with value: 1.0799398402165805.
[I 2025-07-23 21:27:18,735] Trial 8 finished with value: 33.33311852820654 and parameters: {'n_layers': 1, 'n_units': 477, 'activation': 'tanh', 'dropout': 0.11573088287327227, 'optimizer': 'rmsprop', 'learning_rate': 2.2285524449898522e-05, 'batch_size': 512}. Best is trial 5 with value: 1.0799398402165805.
[I 2025-07-23 21:30:09,791] Trial 9 finished with value: 27.247806612248986 and parameters: {'n_layers': 4, 'n_units': 313, 'activation': 'relu', 'dropout': 0.43425255935019486, 'optimizer': 'rmsprop', 'learning_rate': 0.00016467121900001698, 'batch_size': 1024}. Best is trial 5 with value: 1.0799398402165805.
[I 2025-07-23 21:30:57,686] Trial 10 finished with value: 40.1272377575099 and parameters: {'n_layers': 2, 'n_units': 369, 'activation': 'relu', 'dropout': 0.012753695448889213, 'optimizer': 'adam', 'learning_rate': 0.00937377885405193, 'batch_size': 512}. Best is trial 5 with value: 1.0799398402165805.
[I 2025-07-23 21:31:51,125] Trial 11 finished with value: 76.07638135504368 and parameters: {'n_layers': 1, 'n_units': 228, 'activation': 'tanh', 'dropout': 0.3558975512593592, 'optimizer': 'adam', 'learning_rate': 1.014384825015525e-05, 'batch_size': 256}. Best is trial 5 with value: 1.0799398402165805.
[I 2025-07-23 21:33:34,723] Trial 12 finished with value: 0.617670986158356 and parameters: {'n_layers': 1, 'n_units': 269, 'activation': 'tanh', 'dropout': 0.13106453982784788, 'optimizer': 'adam', 'learning_rate': 0.0007364208978473347, 'batch_size': 256}. Best is trial 12 with value: 0.617670986158356.
[I 2025-07-23 21:35:46,781] Trial 13 finished with value: 9.012963460398034 and parameters: {'n_layers': 1, 'n_units': 407, 'activation': 'tanh', 'dropout': 0.1003285287286643, 'optimizer': 'adam', 'learning_rate': 0.0008103989860767329, 'batch_size': 256}. Best is trial 12 with value: 0.617670986158356.
[I 2025-07-23 21:36:18,007] Trial 14 finished with value: 197.2273589020472 and parameters: {'n_layers': 2, 'n_units': 206, 'activation': 'relu', 'dropout': 0.003151892725500094, 'optimizer': 'adam', 'learning_rate': 0.0019145527184574805, 'batch_size': 1024}. Best is trial 12 with value: 0.617670986158356.
[I 2025-07-23 21:37:00,607] Trial 15 finished with value: 49.38208002939478 and parameters: {'n_layers': 3, 'n_units': 325, 'activation': 'tanh', 'dropout': 0.17512177327863632, 'optimizer': 'adam', 'learning_rate': 0.006658300105301903, 'batch_size': 512}. Best is trial 12 with value: 0.617670986158356.
[I 2025-07-23 21:37:44,681] Trial 16 finished with value: 0.3290190885737052 and parameters: {'n_layers': 1, 'n_units': 447, 'activation': 'relu', 'dropout': 0.07875955510387089, 'optimizer': 'adam', 'learning_rate': 0.000989043358901111, 'batch_size': 256}. Best is trial 16 with value: 0.3290190885737052.
[I 2025-07-23 21:38:24,557] Trial 17 finished with value: 9.861486427392432 and parameters: {'n_layers': 1, 'n_units': 257, 'activation': 'tanh', 'dropout': 0.07554063654863438, 'optimizer': 'adam', 'learning_rate': 0.0007189022090601717, 'batch_size': 256}. Best is trial 16 with value: 0.3290190885737052.
[I 2025-07-23 21:59:40,061] Trial 18 finished with value: 5.221430852301764 and parameters: {'n_layers': 1, 'n_units': 345, 'activation': 'relu', 'dropout': 0.044125412933902985, 'optimizer': 'adam', 'learning_rate': 0.00029214861924175195, 'batch_size': 256}. Best is trial 16 with value: 0.3290190885737052.
[I 2025-07-23 22:00:57,467] Trial 19 finished with value: 0.4033923277789542 and parameters: {'n_layers': 1, 'n_units': 182, 'activation': 'tanh', 'dropout': 0.12958972526170132, 'optimizer': 'adam', 'learning_rate': 0.0012043227379167582, 'batch_size': 256}. Best is trial 16 with value: 0.3290190885737052.
[I 2025-07-23 22:01:32,927] Trial 20 finished with value: 0.3891514047941086 and parameters: {'n_layers': 2, 'n_units': 178, 'activation': 'relu', 'dropout': 0.19542176404043557, 'optimizer': 'adam', 'learning_rate': 0.001316236913998907, 'batch_size': 256}. Best is trial 16 with value: 0.3290190885737052.
[I 2025-07-23 22:02:03,746] Trial 21 finished with value: 1.3476560412892018 and parameters: {'n_layers': 2, 'n_units': 198, 'activation': 'relu', 'dropout': 0.19779184890592996, 'optimizer': 'adam', 'learning_rate': 0.001248278740790113, 'batch_size': 256}. Best is trial 16 with value: 0.3290190885737052.
[I 2025-07-23 22:02:56,053] Trial 22 finished with value: 0.30123752921331726 and parameters: {'n_layers': 1, 'n_units': 175, 'activation': 'relu', 'dropout': 0.06450322299884598, 'optimizer': 'adam', 'learning_rate': 0.00033611653995787135, 'batch_size': 256}. Best is trial 22 with value: 0.30123752921331726.
[I 2025-07-23 22:14:16,318] Trial 23 finished with value: 0.2871467187861412 and parameters: {'n_layers': 2, 'n_units': 130, 'activation': 'relu', 'dropout': 0.06450605510608381, 'optimizer': 'adam', 'learning_rate': 0.00028994842485690605, 'batch_size': 256}. Best is trial 23 with value: 0.2871467187861412.
[I 2025-07-23 22:47:20,584] Trial 24 finished with value: 0.3303380128562089 and parameters: {'n_layers': 1, 'n_units': 65, 'activation': 'relu', 'dropout': 0.05902460306020481, 'optimizer': 'adam', 'learning_rate': 0.0002812992929328353, 'batch_size': 256}. Best is trial 23 with value: 0.2871467187861412.
[I 2025-07-23 22:50:03,368] Trial 25 finished with value: 0.32368498892451547 and parameters: {'n_layers': 3, 'n_units': 113, 'activation': 'relu', 'dropout': 0.038623760526782555, 'optimizer': 'adam', 'learning_rate': 0.00012627831154195766, 'batch_size': 256}. Best is trial 23 with value: 0.2871467187861412.
[I 2025-07-23 22:51:27,486] Trial 26 finished with value: 291.74408350053784 and parameters: {'n_layers': 3, 'n_units': 118, 'activation': 'relu', 'dropout': 0.030987289470365297, 'optimizer': 'adam', 'learning_rate': 9.038714565002043e-05, 'batch_size': 1024}. Best is trial 23 with value: 0.2871467187861412.
[I 2025-07-23 22:54:18,817] Trial 27 finished with value: 0.26051136654490814 and parameters: {'n_layers': 3, 'n_units': 149, 'activation': 'relu', 'dropout': 0.0445143120778433, 'optimizer': 'adam', 'learning_rate': 0.0001890553115945911, 'batch_size': 256}. Best is trial 27 with value: 0.26051136654490814.
[I 2025-07-23 22:55:45,366] Trial 28 finished with value: 0.27628181336446045 and parameters: {'n_layers': 3, 'n_units': 156, 'activation': 'relu', 'dropout': 0.08768703304444309, 'optimizer': 'adam', 'learning_rate': 0.0004568663912579332, 'batch_size': 256}. Best is trial 27 with value: 0.26051136654490814.
[I 2025-07-23 22:57:14,334] Trial 29 finished with value: 68.00980315361413 and parameters: {'n_layers': 3, 'n_units': 148, 'activation': 'relu', 'dropout': 0.10063629070074127, 'optimizer': 'adam', 'learning_rate': 0.0004367783361731793, 'batch_size': 1024}. Best is trial 27 with value: 0.26051136654490814.
✅ Best Trial:
{'n_layers': 3, 'n_units': 149, 'activation': 'relu', 'dropout': 0.0445143120778433, 'optimizer': 'adam', 'learning_rate': 0.0001890553115945911, 'batch_size': 256}
(text_analytics) PS C:\Users\pc\Desktop\ANN> 