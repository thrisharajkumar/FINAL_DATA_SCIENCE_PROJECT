{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e99f42",
   "metadata": {},
   "source": [
    "LightGBM - 2nd Classical Model \n",
    "\n",
    "- Train/Validation/Test: 70%-15%-15% internal split from train_for_model.csv\n",
    "\n",
    "- Holdout Evaluation: Evaluate on merged_test_with_features.csv\n",
    "\n",
    "- Generalization Test: Train on merged_train_5_MOSFET.csv and test on merged_test_1_MOSFET.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eccbfc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1102\n",
      "[LightGBM] [Info] Number of data points in the train set: 84438, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "Training completed in 9.07 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Evaluation:\n",
      "Target Output                                  RMSE     R² Score\n",
      "----------------------------------------------------------------\n",
      "voltage_rise_time_pulse1                   3.74E-08       0.0090\n",
      "voltage_rise_time_pulse2                   1.86E-07       0.9998\n",
      "voltage_fall_time_pulse1                   3.70E-08       1.0000\n",
      "voltage_fall_time_pulse2                   7.09E-08       0.9999\n",
      "current_rise_time_pulse1                   8.37E-07       0.9944\n",
      "current_rise_time_pulse2                   1.75E-07       0.9273\n",
      "current_fall_time_pulse1                   5.64E-06       0.7564\n",
      "current_fall_time_pulse2                   3.47E-08       0.2788\n",
      "overshoot_pulse_1                          1.23E+00       0.9979\n",
      "overshoot_pulse_2                          2.59E+00       0.9999\n",
      "undershoot_pulse_1                         4.75E+00       0.9663\n",
      "undershoot_pulse_2                         1.01E+01       0.9380\n",
      "ringing_frequency_MHz                      1.67E+00       0.9986\n",
      "Predictions saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\testing\\validation_predictions.csv\n",
      "Metrics saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\testing\\validation_predictions_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Internal Test Evaluation:\n",
      "Target Output                                  RMSE     R² Score\n",
      "----------------------------------------------------------------\n",
      "voltage_rise_time_pulse1                   2.53E-09       0.6722\n",
      "voltage_rise_time_pulse2                   1.85E-07       0.9998\n",
      "voltage_fall_time_pulse1                   3.64E-08       1.0000\n",
      "voltage_fall_time_pulse2                   6.64E-08       0.9999\n",
      "current_rise_time_pulse1                   6.18E-07       0.9969\n",
      "current_rise_time_pulse2                   1.72E-07       0.9297\n",
      "current_fall_time_pulse1                   5.48E-06       0.7719\n",
      "current_fall_time_pulse2                   1.60E-08       0.5732\n",
      "overshoot_pulse_1                          1.23E+00       0.9979\n",
      "overshoot_pulse_2                          2.57E+00       0.9999\n",
      "undershoot_pulse_1                         4.59E+00       0.9684\n",
      "undershoot_pulse_2                         1.02E+01       0.9315\n",
      "ringing_frequency_MHz                      1.64E+00       0.9986\n",
      "Predictions saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\testing\\internal_test_predictions.csv\n",
      "Metrics saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\testing\\internal_test_predictions_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "External Holdout Evaluation:\n",
      "Target Output                                  RMSE     R² Score\n",
      "----------------------------------------------------------------\n",
      "voltage_rise_time_pulse1                   2.11E-10       0.8859\n",
      "voltage_rise_time_pulse2                   2.32E-07       1.0000\n",
      "voltage_fall_time_pulse1                   9.82E-08       0.9973\n",
      "voltage_fall_time_pulse2                   1.09E-07       0.9993\n",
      "current_rise_time_pulse1                   1.86E-07       0.9999\n",
      "current_rise_time_pulse2                   1.07E-08       0.0460\n",
      "current_fall_time_pulse1                   7.69E-07       0.9195\n",
      "current_fall_time_pulse2                   1.15E-09       0.8431\n",
      "overshoot_pulse_1                          1.14E+00       0.9482\n",
      "overshoot_pulse_2                          5.01E+00       0.9998\n",
      "undershoot_pulse_1                         2.94E+00       0.9346\n",
      "undershoot_pulse_2                         3.82E+00       0.8963\n",
      "ringing_frequency_MHz                      4.66E+00       0.8627\n",
      "Predictions saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\testing\\holdout_predictions.csv\n",
      "Metrics saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\testing\\holdout_predictions_metrics.csv\n",
      "\n",
      "Model and scalers saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\testing\n"
     ]
    }
   ],
   "source": [
    "# Usage: $env:PYTHONPATH=\".\"; python Classical_Models\\LGBM\\lightgbm_train.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "FAST_MODE = True\n",
    "TRAIN_FILE = r\"C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\data\\processed\\train_for_model.csv\"\n",
    "HOLDOUT_FILE = r\"C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\data\\processed\\merged_test_with_features.csv\"\n",
    "MODEL_DIR = r\"C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\testing\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_COLUMNS = [\n",
    "    'voltage_rise_time_pulse1', 'voltage_rise_time_pulse2',\n",
    "    'voltage_fall_time_pulse1', 'voltage_fall_time_pulse2',\n",
    "    'current_rise_time_pulse1', 'current_rise_time_pulse2',\n",
    "    'current_fall_time_pulse1', 'current_fall_time_pulse2',\n",
    "    'overshoot_pulse_1', 'overshoot_pulse_2',\n",
    "    'undershoot_pulse_1', 'undershoot_pulse_2',\n",
    "    'ringing_frequency_MHz'\n",
    "]\n",
    "DROP_COLUMNS = ['DeviceID']\n",
    "\n",
    "# === 1. Load & Sample Training Data ===\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "df.dropna(subset=TARGET_COLUMNS, inplace=True)\n",
    "if 'Device' in df.columns:\n",
    "    df = df.drop(columns=['Device'])\n",
    "\n",
    "if FAST_MODE:\n",
    "    df = df.sample(frac=0.25, random_state=42)\n",
    "\n",
    "X = df.drop(columns=DROP_COLUMNS + TARGET_COLUMNS)\n",
    "y = df[TARGET_COLUMNS]\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
    "\n",
    "# === 2. Scaling ===\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_val_scaled = scaler_y.transform(y_val)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "joblib.dump(scaler_X, os.path.join(MODEL_DIR, \"input_scaler.pkl\"))\n",
    "joblib.dump(scaler_y, os.path.join(MODEL_DIR, \"output_scaler.pkl\"))\n",
    "\n",
    "# === 3. Train LightGBM ===\n",
    "lgb_params = {\n",
    "    \"n_estimators\": 100 if FAST_MODE else 300,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "model = MultiOutputRegressor(lgb.LGBMRegressor(**lgb_params))\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "print(f\"Training completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# === 4. Enhanced Evaluation Function ===\n",
    "def evaluate(model, X_scaled, y_scaled, label, save_name):\n",
    "    y_pred_scaled = model.predict(X_scaled)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_true = scaler_y.inverse_transform(y_scaled)\n",
    "\n",
    "    # === Compute RMSE and R²\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred, multioutput='raw_values'))\n",
    "    r2 = r2_score(y_true, y_pred, multioutput='raw_values')\n",
    "\n",
    "    # === Pretty print results\n",
    "    print(f\"\\n{label} Evaluation:\")\n",
    "    print(f\"{'Target Output':<35} {'RMSE':>15} {'R² Score':>12}\")\n",
    "    print(\"-\" * 64)\n",
    "    for i, col in enumerate(TARGET_COLUMNS):\n",
    "        rmse_sci = f\"{rmse[i]:.2E}\"\n",
    "        r2_val = f\"{r2[i]:.4f}\"\n",
    "        print(f\"{col:<35} {rmse_sci:>15} {r2_val:>12}\")\n",
    "\n",
    "    # === Save predictions (actual vs predicted)\n",
    "    df_result = pd.DataFrame({\n",
    "        f\"{col}_actual\": y_true[:, i] for i, col in enumerate(TARGET_COLUMNS)\n",
    "    })\n",
    "    for i, col in enumerate(TARGET_COLUMNS):\n",
    "        df_result[f\"{col}_predicted\"] = y_pred[:, i]\n",
    "\n",
    "    predictions_path = os.path.join(MODEL_DIR, save_name)\n",
    "    df_result.to_csv(predictions_path, index=False)\n",
    "    print(f\"Predictions saved to: {predictions_path}\")\n",
    "\n",
    "    # === Save RMSE + R² metrics\n",
    "    df_metrics = pd.DataFrame({\n",
    "        \"Target\": TARGET_COLUMNS,\n",
    "        \"RMSE\": [f\"{val:.2E}\" for val in rmse],\n",
    "        \"R2_Score\": [round(val, 4) for val in r2]\n",
    "    })\n",
    "\n",
    "    metrics_filename = save_name.replace(\".csv\", \"_metrics.csv\")\n",
    "    metrics_path = os.path.join(MODEL_DIR, metrics_filename)\n",
    "    df_metrics.to_csv(metrics_path, index=False)\n",
    "    print(f\"Metrics saved to: {metrics_path}\")\n",
    "\n",
    "# === 5. Evaluate All Splits ===\n",
    "evaluate(model, X_val_scaled, y_val_scaled, \"Validation\", \"validation_predictions.csv\")\n",
    "evaluate(model, X_test_scaled, y_test_scaled, \"Internal Test\", \"internal_test_predictions.csv\")\n",
    "\n",
    "# === 6. Evaluate on Holdout Test ===\n",
    "df_holdout = pd.read_csv(HOLDOUT_FILE)\n",
    "df_holdout.dropna(subset=TARGET_COLUMNS, inplace=True)\n",
    "if 'Device' in df_holdout.columns:\n",
    "    df_holdout = df_holdout.drop(columns=['Device'])\n",
    "\n",
    "X_holdout = df_holdout.drop(columns=DROP_COLUMNS + TARGET_COLUMNS)\n",
    "y_holdout = df_holdout[TARGET_COLUMNS]\n",
    "X_holdout_scaled = scaler_X.transform(X_holdout)\n",
    "y_holdout_scaled = scaler_y.transform(y_holdout)\n",
    "\n",
    "evaluate(model, X_holdout_scaled, y_holdout_scaled, \"External Holdout\", \"holdout_predictions.csv\")\n",
    "\n",
    "# === 7. Save Final Model ===\n",
    "joblib.dump(model, os.path.join(MODEL_DIR, \"model.pkl\"))\n",
    "print(f\"\\nModel and scalers saved to: {MODEL_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66af61f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 337756, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training completed in 104.30 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Evaluation:\n",
      "Target Output                                  RMSE     R² Score\n",
      "----------------------------------------------------------------\n",
      "voltage_rise_time_pulse1                   1.89E-08       0.0299\n",
      "voltage_rise_time_pulse2                   1.50E-07       0.9999\n",
      "voltage_fall_time_pulse1                   3.42E-09       1.0000\n",
      "voltage_fall_time_pulse2                   5.62E-08       0.9999\n",
      "current_rise_time_pulse1                   6.69E-07       0.9965\n",
      "current_rise_time_pulse2                   1.60E-07       0.9387\n",
      "current_fall_time_pulse1                   4.73E-06       0.8159\n",
      "current_fall_time_pulse2                   2.25E-08       0.4068\n",
      "overshoot_pulse_1                          7.50E-01       0.9992\n",
      "overshoot_pulse_2                          1.19E+00       1.0000\n",
      "undershoot_pulse_1                         3.19E+00       0.9844\n",
      "undershoot_pulse_2                         8.27E+00       0.9550\n",
      "ringing_frequency_MHz                      1.16E+00       0.9993\n",
      "Predictions saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\ttrain_full\\validation_predictions.csv\n",
      "Metrics saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\ttrain_full\\validation_predictions_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Internal Test Evaluation:\n",
      "Target Output                                  RMSE     R² Score\n",
      "----------------------------------------------------------------\n",
      "voltage_rise_time_pulse1                   1.68E-08       0.2314\n",
      "voltage_rise_time_pulse2                   1.46E-07       0.9999\n",
      "voltage_fall_time_pulse1                   3.26E-09       1.0000\n",
      "voltage_fall_time_pulse2                   5.07E-08       0.9999\n",
      "current_rise_time_pulse1                   6.62E-07       0.9966\n",
      "current_rise_time_pulse2                   1.57E-07       0.9411\n",
      "current_fall_time_pulse1                   4.85E-06       0.8171\n",
      "current_fall_time_pulse2                   2.76E-08       0.3252\n",
      "overshoot_pulse_1                          7.37E-01       0.9992\n",
      "overshoot_pulse_2                          1.20E+00       1.0000\n",
      "undershoot_pulse_1                         2.10E+04       0.0000\n",
      "undershoot_pulse_2                         7.92E+00       0.9588\n",
      "ringing_frequency_MHz                      1.15E+00       0.9993\n",
      "Predictions saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\ttrain_full\\internal_test_predictions.csv\n",
      "Metrics saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\ttrain_full\\internal_test_predictions_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "External Holdout Evaluation:\n",
      "Target Output                                  RMSE     R² Score\n",
      "----------------------------------------------------------------\n",
      "voltage_rise_time_pulse1                   1.43E-10       0.9474\n",
      "voltage_rise_time_pulse2                   2.55E-09       1.0000\n",
      "voltage_fall_time_pulse1                   8.59E-09       1.0000\n",
      "voltage_fall_time_pulse2                   8.75E-09       1.0000\n",
      "current_rise_time_pulse1                   5.50E-08       1.0000\n",
      "current_rise_time_pulse2                   5.45E-09       0.7538\n",
      "current_fall_time_pulse1                   3.20E-07       0.9861\n",
      "current_fall_time_pulse2                   5.88E-10       0.9593\n",
      "overshoot_pulse_1                          6.10E-01       0.9852\n",
      "overshoot_pulse_2                          1.00E+00       1.0000\n",
      "undershoot_pulse_1                         1.68E+00       0.9787\n",
      "undershoot_pulse_2                         1.98E+00       0.9721\n",
      "ringing_frequency_MHz                      3.87E+00       0.9050\n",
      "Predictions saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\ttrain_full\\holdout_predictions.csv\n",
      "Metrics saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\ttrain_full\\holdout_predictions_metrics.csv\n",
      "\n",
      "Model and scalers saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\ttrain_full\n"
     ]
    }
   ],
   "source": [
    "# Usage: $env:PYTHONPATH=\".\"; python Classical_Models\\LGBM\\lightgbm_train.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "FAST_MODE = True\n",
    "TRAIN_FILE = r\"C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\data\\processed\\train_for_model.csv\"\n",
    "HOLDOUT_FILE = r\"C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\data\\processed\\merged_test_with_features.csv\"\n",
    "MODEL_DIR = r\"C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\ttrain_full\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_COLUMNS = [\n",
    "    'voltage_rise_time_pulse1', 'voltage_rise_time_pulse2',\n",
    "    'voltage_fall_time_pulse1', 'voltage_fall_time_pulse2',\n",
    "    'current_rise_time_pulse1', 'current_rise_time_pulse2',\n",
    "    'current_fall_time_pulse1', 'current_fall_time_pulse2',\n",
    "    'overshoot_pulse_1', 'overshoot_pulse_2',\n",
    "    'undershoot_pulse_1', 'undershoot_pulse_2',\n",
    "    'ringing_frequency_MHz'\n",
    "]\n",
    "DROP_COLUMNS = ['DeviceID']\n",
    "\n",
    "# === 1. Load & Sample Training Data ===\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "df.dropna(subset=TARGET_COLUMNS, inplace=True)\n",
    "if 'Device' in df.columns:\n",
    "    df = df.drop(columns=['Device'])\n",
    "\n",
    "X = df.drop(columns=DROP_COLUMNS + TARGET_COLUMNS)\n",
    "y = df[TARGET_COLUMNS]\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
    "\n",
    "# === 2. Scaling ===\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_val_scaled = scaler_y.transform(y_val)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "joblib.dump(scaler_X, os.path.join(MODEL_DIR, \"input_scaler.pkl\"))\n",
    "joblib.dump(scaler_y, os.path.join(MODEL_DIR, \"output_scaler.pkl\"))\n",
    "\n",
    "# === 3. Train LightGBM ===\n",
    "lgb_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "model = MultiOutputRegressor(lgb.LGBMRegressor(**lgb_params))\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "print(f\"Training completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# === 4. Enhanced Evaluation Function ===\n",
    "def evaluate(model, X_scaled, y_scaled, label, save_name):\n",
    "    y_pred_scaled = model.predict(X_scaled)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_true = scaler_y.inverse_transform(y_scaled)\n",
    "\n",
    "    # === Compute RMSE and R²\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred, multioutput='raw_values'))\n",
    "    r2 = r2_score(y_true, y_pred, multioutput='raw_values')\n",
    "\n",
    "    # === Pretty print results\n",
    "    print(f\"\\n{label} Evaluation:\")\n",
    "    print(f\"{'Target Output':<35} {'RMSE':>15} {'R² Score':>12}\")\n",
    "    print(\"-\" * 64)\n",
    "    for i, col in enumerate(TARGET_COLUMNS):\n",
    "        rmse_sci = f\"{rmse[i]:.2E}\"\n",
    "        r2_val = f\"{r2[i]:.4f}\"\n",
    "        print(f\"{col:<35} {rmse_sci:>15} {r2_val:>12}\")\n",
    "\n",
    "    # === Save predictions (actual vs predicted)\n",
    "    df_result = pd.DataFrame({\n",
    "        f\"{col}_actual\": y_true[:, i] for i, col in enumerate(TARGET_COLUMNS)\n",
    "    })\n",
    "    for i, col in enumerate(TARGET_COLUMNS):\n",
    "        df_result[f\"{col}_predicted\"] = y_pred[:, i]\n",
    "\n",
    "    predictions_path = os.path.join(MODEL_DIR, save_name)\n",
    "    df_result.to_csv(predictions_path, index=False)\n",
    "    print(f\"Predictions saved to: {predictions_path}\")\n",
    "\n",
    "    # === Save RMSE + R² metrics\n",
    "    df_metrics = pd.DataFrame({\n",
    "        \"Target\": TARGET_COLUMNS,\n",
    "        \"RMSE\": [f\"{val:.2E}\" for val in rmse],\n",
    "        \"R2_Score\": [round(val, 4) for val in r2]\n",
    "    })\n",
    "\n",
    "    metrics_filename = save_name.replace(\".csv\", \"_metrics.csv\")\n",
    "    metrics_path = os.path.join(MODEL_DIR, metrics_filename)\n",
    "    df_metrics.to_csv(metrics_path, index=False)\n",
    "    print(f\"Metrics saved to: {metrics_path}\")\n",
    "\n",
    "# === 5. Evaluate All Splits ===\n",
    "evaluate(model, X_val_scaled, y_val_scaled, \"Validation\", \"validation_predictions.csv\")\n",
    "evaluate(model, X_test_scaled, y_test_scaled, \"Internal Test\", \"internal_test_predictions.csv\")\n",
    "\n",
    "# === 6. Evaluate on Holdout Test ===\n",
    "df_holdout = pd.read_csv(HOLDOUT_FILE)\n",
    "df_holdout.dropna(subset=TARGET_COLUMNS, inplace=True)\n",
    "if 'Device' in df_holdout.columns:\n",
    "    df_holdout = df_holdout.drop(columns=['Device'])\n",
    "\n",
    "X_holdout = df_holdout.drop(columns=DROP_COLUMNS + TARGET_COLUMNS)\n",
    "y_holdout = df_holdout[TARGET_COLUMNS]\n",
    "X_holdout_scaled = scaler_X.transform(X_holdout)\n",
    "y_holdout_scaled = scaler_y.transform(y_holdout)\n",
    "\n",
    "evaluate(model, X_holdout_scaled, y_holdout_scaled, \"External Holdout\", \"holdout_predictions.csv\")\n",
    "\n",
    "# === 7. Save Final Model ===\n",
    "joblib.dump(model, os.path.join(MODEL_DIR, \"model.pkl\"))\n",
    "print(f\"\\nModel and scalers saved to: {MODEL_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "656e06eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 481645, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training completed in 130.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization (Unseen MOSFET) Evaluation:\n",
      "Target Output                                  RMSE     R² Score\n",
      "----------------------------------------------------------------\n",
      "voltage_rise_time_pulse1            2.13E-08       0.0233\n",
      "voltage_rise_time_pulse2            3.78E-07       0.0687\n",
      "voltage_fall_time_pulse1            8.40E-09      -5.7392\n",
      "voltage_fall_time_pulse2            5.68E-08       0.6886\n",
      "current_rise_time_pulse1            8.61E-07       0.6286\n",
      "current_rise_time_pulse2            8.53E-07      -0.0997\n",
      "current_fall_time_pulse1            7.55E-06       0.3638\n",
      "current_fall_time_pulse2            2.98E-08      -0.3102\n",
      "overshoot_pulse_1                   1.79E+01       0.4983\n",
      "overshoot_pulse_2                   1.32E+01       0.8971\n",
      "undershoot_pulse_1                  1.15E+03   -1626.0109\n",
      "undershoot_pulse_2                  2.53E+01       0.6542\n",
      "ringing_frequency_MHz               3.64E+01     -28.7590\n",
      "Results saved to: unseen_predictions.csv and unseen_predictions_metrics.csv\n",
      "\n",
      "Model and scalers saved to: C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\generalization\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage: $env:PYTHONPATH=\".\"; python Classical_Models\\LGBM\\lightgbm_generalization.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "FAST_MODE = True\n",
    "TRAIN_FILE = r\"C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\data\\raw\\merged_train_5_MOSFETS.csv\"\n",
    "TEST_FILE = r\"C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\data\\raw\\merged_test_1_MOSFET.csv\"\n",
    "MODEL_DIR = r\"C:\\Users\\pc\\Desktop\\PROJECT_THESIS_Thrisha_Rajkumar\\Classical_Models\\models\\lightgbm\\generalization\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_COLUMNS = [\n",
    "    'voltage_rise_time_pulse1', 'voltage_rise_time_pulse2',\n",
    "    'voltage_fall_time_pulse1', 'voltage_fall_time_pulse2',\n",
    "    'current_rise_time_pulse1', 'current_rise_time_pulse2',\n",
    "    'current_fall_time_pulse1', 'current_fall_time_pulse2',\n",
    "    'overshoot_pulse_1', 'overshoot_pulse_2',\n",
    "    'undershoot_pulse_1', 'undershoot_pulse_2',\n",
    "    'ringing_frequency_MHz'\n",
    "]\n",
    "DROP_COLUMNS = ['DeviceID']\n",
    "\n",
    "# === 1. Load & Sample Training Data ===\n",
    "df_train = pd.read_csv(TRAIN_FILE)\n",
    "df_train.dropna(subset=TARGET_COLUMNS, inplace=True)\n",
    "if 'Device' in df_train.columns:\n",
    "    df_train = df_train.drop(columns=['Device'])\n",
    "\n",
    "X_train = df_train.drop(columns=DROP_COLUMNS + TARGET_COLUMNS)\n",
    "y_train = df_train[TARGET_COLUMNS]\n",
    "\n",
    "# === 2. Load Unseen Test Data ===\n",
    "df_test = pd.read_csv(TEST_FILE)\n",
    "df_test.dropna(subset=TARGET_COLUMNS, inplace=True)\n",
    "if 'Device' in df_test.columns:\n",
    "    df_test = df_test.drop(columns=['Device'])\n",
    "\n",
    "X_test = df_test.drop(columns=DROP_COLUMNS + TARGET_COLUMNS)\n",
    "y_test = df_test[TARGET_COLUMNS]\n",
    "\n",
    "# === 3. Scaling ===\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "joblib.dump(scaler_X, os.path.join(MODEL_DIR, \"input_scaler.pkl\"))\n",
    "joblib.dump(scaler_y, os.path.join(MODEL_DIR, \"output_scaler.pkl\"))\n",
    "\n",
    "# === 4. Train LightGBM ===\n",
    "lgb_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "model = MultiOutputRegressor(lgb.LGBMRegressor(**lgb_params))\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "print(f\"Training completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# === 5. Evaluation ===\n",
    "def evaluate(model, X_scaled, y_scaled, label, save_name):\n",
    "    y_pred_scaled = model.predict(X_scaled)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_true = scaler_y.inverse_transform(y_scaled)\n",
    "\n",
    "    # === Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred, multioutput='raw_values'))\n",
    "    r2 = r2_score(y_true, y_pred, multioutput='raw_values')\n",
    "\n",
    "    print(f\"\\n{label} Evaluation:\")\n",
    "    print(f\"{'Target Output':<35} {'RMSE':>15} {'R² Score':>12}\")\n",
    "    print(\"-\" * 64)\n",
    "    for i, col in enumerate(TARGET_COLUMNS):\n",
    "        print(f\"{col:<35} {rmse[i]:.2E} {r2[i]:>12.4f}\")\n",
    "\n",
    "    # === Save predictions\n",
    "    df_result = pd.DataFrame({f\"{col}_actual\": y_true[:, i] for i, col in enumerate(TARGET_COLUMNS)})\n",
    "    for i, col in enumerate(TARGET_COLUMNS):\n",
    "        df_result[f\"{col}_predicted\"] = y_pred[:, i]\n",
    "    df_result.to_csv(os.path.join(MODEL_DIR, save_name), index=False)\n",
    "\n",
    "    # === Save metrics\n",
    "    df_metrics = pd.DataFrame({\n",
    "        \"Target\": TARGET_COLUMNS,\n",
    "        \"RMSE\": [f\"{val:.2E}\" for val in rmse],\n",
    "        \"R2_Score\": [round(val, 4) for val in r2]\n",
    "    })\n",
    "    metrics_filename = save_name.replace(\".csv\", \"_metrics.csv\")\n",
    "    df_metrics.to_csv(os.path.join(MODEL_DIR, metrics_filename), index=False)\n",
    "    print(f\"Results saved to: {save_name} and {metrics_filename}\")\n",
    "\n",
    "# === 6. Evaluate on Unseen Test ===\n",
    "evaluate(model, X_test_scaled, y_test_scaled, \"Generalization (Unseen MOSFET)\", \"unseen_predictions.csv\")\n",
    "\n",
    "# === 7. Save Model ===\n",
    "joblib.dump(model, os.path.join(MODEL_DIR, \"model.pkl\"))\n",
    "print(f\"\\nModel and scalers saved to: {MODEL_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f2c42",
   "metadata": {},
   "source": [
    "Generalization (Unseen MOSFET) Evaluation:\n",
    "Target Output                                  RMSE     R² Score\n",
    "----------------------------------------------------------------\n",
    "voltage_rise_time_pulse1            2.13E-08       0.0233\n",
    "voltage_rise_time_pulse2            3.78E-07       0.0687\n",
    "voltage_fall_time_pulse1            8.40E-09      -5.7392\n",
    "voltage_fall_time_pulse2            5.68E-08       0.6886\n",
    "current_rise_time_pulse1            8.61E-07       0.6286\n",
    "current_rise_time_pulse2            8.53E-07      -0.0997\n",
    "current_fall_time_pulse1            7.55E-06       0.3638\n",
    "current_fall_time_pulse2            2.98E-08      -0.3102\n",
    "overshoot_pulse_1                   1.79E+01       0.4983\n",
    "overshoot_pulse_2                   1.32E+01       0.8971\n",
    "undershoot_pulse_1                  1.15E+03   -1626.0109\n",
    "undershoot_pulse_2                  2.53E+01       0.6542\n",
    "ringing_frequency_MHz               3.64E+01     -28.7590\n",
    "Results saved to: unseen_predictions.csv and unseen_predictions_metrics.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
